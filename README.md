# arxiv Interested Paper
- Is Medical Chest X-ray Data Anonymous? [`paper`](https://arxiv.org/pdf/2103.08562.pdf)
- Reading Race: AI Recognises Patient's Racial Identity In Medical Images [`paper`](https://arxiv.org/pdf/2107.10356.pdf)
- Predicting brain-age from raw T1-weighted Magnetic Resonance Imaging data using 3D Convolutional Neural Networks [`paper`](https://arxiv.org/pdf/2103.11695.pdf)
- Perceiver: General Perception with Iterative Attention [`paper`](https://arxiv.org/pdf/2103.03206.pdf)
- Trends and Focus of Machine Learning Applications for Health Research [`paper`](https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2753523)
- Going deeper with Image Transformers [`paper`](https://arxiv.org/pdf/2103.17239.pdf)
- Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers
- An Image is Worth 16x16 Words, What is a Video Worth?[`paper`](https://arxiv.org/pdf/2103.13915.pdf)
- CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification [`paper`](https://arxiv.org/pdf/2103.14899.pdf)[`github`](https://github.com/rishikksh20/CrossViT-pytorch)
- CvT: Introducing Convolutions to Vision Transformers [`paper`](https://arxiv.org/pdf/2103.15808.pdf)
- Training Deep Capsule Networks with Residual Connections [`paper`](https://arxiv.org/pdf/2104.07393.pdf)
- Multi-Modal Fusion Transformer for End-to-End Autonomous Driving [`paper`](https://arxiv.org/pdf/2104.09224.pdf)
- Activate or Not: Learning Customized Activation [`paper`](https://arxiv.org/pdf/2009.04759.pdf)
- Loss odyssey in medical image segmentation [`paper`](https://www.sciencedirect.com/science/article/pii/S1361841521000815)
- Medical Transformer: Universal Brain Encoder for 3D MRI Analysis[`paper`](https://arxiv.org/pdf/2104.13633.pdf)
- Dynamic Attentive Graph Learning for Image Restoration [`paper`](https://openaccess.thecvf.com/content/ICCV2021/papers/Mou_Dynamic_Attentive_Graph_Learning_for_Image_Restoration_ICCV_2021_paper.pdf)
- CAN AN IMAGE CLASSIFIER SUFFICE FOR ACTION RECOGNITION? [`paper`](https://openreview.net/pdf?id=qhkFX-HLuHV)
- Dynamics of Disruption in Science and Technology [`paper`](https://arxiv.org/pdf/2106.11184v1.pdf)
- R-Drop: Regularized Dropout for Neural Networks
- Attention Bottlenecks for Multimodal Fusion [`paper`](https://arxiv.org/pdf/2107.00135.pdf)
- Perceptual Score: What Data Modalities Does Your Model Perceive?[`paper`](https://papers.nips.cc/paper/2021/file/b51a15f382ac914391a58850ab343b00-Paper.pdf)
- DISCOVERING AND EXPLAINING THE REPRESENTA- TION BOTTLENECK OF DNNS[`paper`](https://openreview.net/pdf?id=iRCUlgmdfHJ)
- RELATIONAL MULTI-TASK LEARNING: MODELING RELATIONS BETWEEN DATA AND TASKS [`paper`](https://openreview.net/pdf?id=8Py-W8lSUgy)
- BBN: Bilateral-Branch Network With Cumulative Learning for Long-Tailed Visual Recognition [`paper`](https://arxiv.org/pdf/1912.02413.pdf)
- BatchFormer: Learning to Explore Sample Relationships for Robust Representation Learning [`paper`](https://arxiv.org/pdf/2203.01522.pdf)
- OLO: Vision Outlooker for Visual Recognition [`paper`](https://arxiv.org/pdf/2106.13112.pdf?ref=https://codemonkey.link)
- 
# Transformer
- DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification [`paper`](https://papers.nips.cc/paper/2021/file/747d3443e319a22747fbb873e8b2f9f2-Paper.pdf)
- Glance-and-Gaze Vision Transformer [`paper`](https://papers.nips.cc/paper/2021/file/6c524f9d5d7027454a783c841250ba71-Paper.pdf)
- ResT: An Efficient Transformer for Visual Recognition[`paper`](https://papers.nips.cc/paper/2021/file/82c2559140b95ccda9c6ca4a8b981f1e-Paper.pdf)
- Focal Attention for Long-Range Interactions in Vision Transformers [`paper`](https://papers.nips.cc/paper/2021/file/fc1a36821b02abbd2503fd949bfc9131-Paper.pdf)
- CrossFormer: A VERSATILE VISION TRANSFORMER HINGING ON CROSS-SCALE ATTENTION [`paper`](https://arxiv.org/pdf/2108.00154.pdf?ref=https://githubhelp.com)[`code`](https://github.com/cheerss/CrossFormer)
- Dynamic Grained Encoder for Vision Transformers [`paper`](https://openreview.net/pdf?id=gnAIV-EKw2)
- Efficient Training of Visual Transformers with Small Datasets [`paper`](https://openreview.net/pdf?id=SCN8UaetXx)
- Not All Images are Worth 16x16 Words: Dynamic Transformers for Efficient Image Recognition [`paper`](https://papers.nips.cc/paper/2021/file/64517d8435994992e682b3e4aa0a0661-Paper.pdf)
- All Tokens Matter: Token Labeling for Training Better Vision Transformers[`paper`](https://papers.nips.cc/paper/2021/file/9a49a25d845a483fae4be7e341368e36-Paper.pdf)
- Multi-class Token Transformer for Weakly Supervised Semantic Segmentation [`paper`](https://arxiv.org/pdf/2203.02891.pdf)
- MetaFormer : A Unified Meta Framework for Fine-Grained Recognition[`paper`](https://arxiv.org/pdf/2203.02751.pdf)[`github`](https://github.com/dqshuai/MetaFormer)
- Coarse-to-Fine Vision Transformer [`paper`](https://arxiv.org/pdf/2203.03821.pdf)[`github`](https://github.com/ChenMnZ/CF-ViT/blob/53ad1366f287c9a6488a5f237ad38a63b9f1ed0f/lvvit/models/lvvit.py#L33)

# Face Aging
- Continuous Face Aging via Self-estimated Residual Age Embedding[`paper`](https://arxiv.org/pdf/2105.00020.pdf)
- How Does Loss Function Affect Generalization Performance of Deep Learning? Application to Human Age Estimation[`paper`](http://proceedings.mlr.press/v139/akbari21a/akbari21a.pdf)
- Delving into Deep Imbalanced Regression[`paper`](http://proceedings.mlr.press/v139/yang21m/yang21m.pdf)
- Self-Paced Deep Regression Forests with Consideration on Ranking Fairness [`paper`](https://arxiv.org/pdf/2112.06455.pdf)
- Ranking [`paper code`](https://paperswithcode.com/paper/consistent-rank-logits-for-ordinal-regression)
- Learning Probabilistic Ordinal Embeddings for Uncertainty-Aware Regression [`paper`](https://arxiv.org/pdf/2103.13629.pdf)[`github`](https://github.com/Li-Wanhua/POEs)
- Balanced MSE for Imbalanced Visual Regression [`paper`](https://arxiv.org/pdf/2203.16427.pdf)
- Unimodal-Concentrated Loss: Fully Adaptive Label Distribution Learning for Ordinal Regression

# Others
- What social media told us in the time of COVID-19: a scoping review[`paper`](https://www.thelancet.com/action/showPdf?pii=S2589-7500%2820%2930315-0)
- Partial success in closing the gap between human and machine vision [`paper`](https://openreview.net/pdf?id=QkljT4mrfs)

# Brain aging
- Voxel-level Importance Maps for Interpretable Brain Age Estimation [`paper`](https://arxiv.org/pdf/2108.05388.pdf)

# Interpreting
- Towards Interpretable Deep Networks for Monocular Depth Estimation [`paper`](https://arxiv.org/pdf/2108.05312v1.pdf)

# segmentation
- SCS-Net: A Scale and Context Sensitive Network for Retinal Vessel Segmentation
- Global-and-Local Collaborative Learning for Co-Salient Object Detection [`paper`](https://arxiv.org/pdf/2204.08917.pdf)

# Others
- Propagating Uncertainty Across Cascaded Medical Imaging Tasks for Improved Deep Learning Inference 

# Inspired
- An End-to-End Transformer Model for Crowd Localization

# Nature
- Brain charts for the human lifespan [`paper`](https://www.nature.com/articles/s41586-022-04554-y)[`response`](https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-022-04554-y/MediaObjects/41586_2022_4554_MOESM11_ESM.pdf)

# Training loss
- Mean-Variance Loss for Deep Age Estimation from a Face [`paper`](https://openaccess.thecvf.com/content_cvpr_2018/papers/Pan_Mean-Variance_Loss_for_CVPR_2018_paper.pdf)[`github`](https://github.com/Herosan163/AgeEstimation)
- PML: Progressive Margin Loss for Long-tailed Age Classification [`paper`](https://arxiv.org/pdf/2103.02140v1.pdf)
- A Flatter Loss for Bias Mitigation in Cross-dataset Facial Age Estimation [`paper`](https://arxiv.org/pdf/2010.10368.pdf)
- Adaptive Mean-Residue Loss for Robust Facial Age Estimation [`paper`](https://arxiv.org/pdf/2203.17156v1.pdf)

reference:

- Adaptive Variance Based Label Distribution Learning For Facial Age Estimation [`paper`](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123680375.pdf)
- Distilling Ordinal Relation and Dark Knowledge for Facial Age Estimation [`paper`](https://www.southampton.ac.uk/~sqc/listP/TNLS2021-Jul.pdf)
